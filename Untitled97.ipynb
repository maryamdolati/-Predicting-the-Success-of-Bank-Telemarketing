{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIV6exhDZSLbnKRb3Ps8mB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryamdolati/-Predicting-the-Success-of-Bank-Telemarketing/blob/main/Untitled97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsjQXJCeoxDZ",
        "outputId": "40aa9e5b-d862-4a30-9735-a383e6c4bf5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SubmissionsIn/SDMVC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNzyKV1_pcnY",
        "outputId": "78dc0a0e-1cd7-492e-9ccc-53853c644c77"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SDMVC'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 43 (delta 18), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (43/43), 2.21 MiB | 8.55 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUxMx9sTptMr",
        "outputId": "4cbe9d4c-4700-4855-bc32-baa4f8eec67e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-preprocessing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-XmYdEXqSjo",
        "outputId": "1945fd4b-ec2f-4d72-d15e-f13312ff2fef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m863.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.16.0)\n",
            "Installing collected packages: keras-preprocessing\n",
            "Successfully installed keras-preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "NuG7jakIriLb",
        "outputId": "a5e46628-cb84-42a6-dd05-37ead5ad6426"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras_preprocessing import image\n",
        "from PIL import Image\n",
        "from numpy import hstack\n",
        "from scipy import misc\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as scio\n",
        "from sklearn.preprocessing import normalize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "path = '/content/drive/MyDrive/data'\n",
        "\n",
        "def Fashion_MV():\n",
        "    a = 0\n",
        "    if a == 1:\n",
        "        from tensorflow.keras.datasets import fashion_mnist\n",
        "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "        x1 = x_test\n",
        "        y = y_test\n",
        "        x2 = np.copy(x1)\n",
        "        x3 = np.copy(x1)\n",
        "        x4 = np.copy(x1)\n",
        "        for i in range(len(y)):\n",
        "            xb = np.where(y_train == y[i])\n",
        "            xb = xb[0][0:2000]\n",
        "            rand = np.random.randint(0, len(xb), 1)\n",
        "            x2[i] = x_train[xb[rand]]\n",
        "        for i in range(len(y)):\n",
        "            xb = np.where(y_train == y[i])\n",
        "            xb = xb[0][2000:4000]\n",
        "            rand = np.random.randint(0, len(xb), 1)\n",
        "            x3[i] = x_train[xb[rand]]\n",
        "        for i in range(len(y)):\n",
        "            xb = np.where(y_train == y[i])\n",
        "            xb = xb[0][4000:6000]\n",
        "            rand = np.random.randint(0, len(xb), 1)\n",
        "            x4[i] = x_train[xb[rand]]\n",
        "        x1 = x4.reshape([-1, 28, 28, 1]) / 255.0\n",
        "        x2 = x2.reshape([-1, 28, 28, 1]) / 255.0\n",
        "        x3 = x3.reshape([-1, 28, 28, 1]) / 255.0\n",
        "        scio.savemat(path + '/3V_Fashion_MV.mat', {'X1': x1, 'X2': x2, 'X3': x3, 'Y': y})\n",
        "\n",
        "    data = scio.loadmat(path + \"/3V_Fashion_MV.mat\")\n",
        "    print(data.keys())\n",
        "\n",
        "    x1 = data['X1']\n",
        "    x2 = data['X2']\n",
        "    x3 = data['X3']\n",
        "    Y = data['Y'][0]\n",
        "    ge = np.random.randint(0, len(x1), 1, dtype=int)\n",
        "    image1 = np.reshape(x1[ge], (28, 28))\n",
        "    image2 = np.reshape(x2[ge], (28, 28))\n",
        "    image3 = np.reshape(x3[ge], (28, 28))\n",
        "    print(Y[ge][0])\n",
        "\n",
        "    plt.figure('Fmnist-v1')\n",
        "    plt.imshow(image1)\n",
        "    plt.pause(0.001)  # Use plt.pause to ensure the plot is displayed\n",
        "    plt.figure('Fmnist-v2')\n",
        "    plt.imshow(image2)\n",
        "    plt.pause(0.001)\n",
        "    plt.figure('Fmnist-v3')\n",
        "    plt.imshow(image3)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    print(x1.shape)\n",
        "    print(x2.shape)\n",
        "    print(x3.shape)\n",
        "    print(Y.shape)\n",
        "\n",
        "    return [x1, x2, x3], Y\n",
        "\n",
        "Fashion_MV()\n",
        "plt.ioff()  # Turn off interactive mode\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def Get_MNIST_USPS_From_COMIC():\n",
        "    data = 0\n",
        "    if data == 1:\n",
        "        x = scio.loadmat(path + \"/MNIST-USPS.mat\")\n",
        "        print(x)\n",
        "        x1 = x['X1']\n",
        "        x2 = x['X2']\n",
        "        Y = x['Y']\n",
        "        print(x1.shape)\n",
        "        print(x2.shape)\n",
        "        print(Y.shape)\n",
        "        print(x1[0])\n",
        "        print(x2[0])\n",
        "        print(Y[0])\n",
        "        x1 = x1.reshape((5000, 28, 28))\n",
        "        x2 = x2.reshape((5000, 16, 16), order='A')\n",
        "        print(Y)\n",
        "        Y = Y[0].reshape(5000,)\n",
        "        print(Y)\n",
        "        xu_reshape = np.zeros([len(x2), 28, 28], dtype=float)\n",
        "        for i in range(len(x2)):\n",
        "            for x in range(16):\n",
        "                for y in range(16):\n",
        "                    xu_reshape[i][x + 6][y + 6] = x2[i][x][y]\n",
        "\n",
        "        print(x1.shape)\n",
        "        print(xu_reshape.shape)\n",
        "        print(Y.shape)\n",
        "        z = np.linspace(0, len(Y) - 1, len(Y), dtype=int)\n",
        "        np.random.shuffle(z)\n",
        "        # print(z)\n",
        "        # print(y_label)\n",
        "        x_data_m = x1\n",
        "        x_data_u = xu_reshape\n",
        "        y_label = Y\n",
        "        x_shuffle_m = np.copy(x_data_m)\n",
        "        x_shuffle_u = np.copy(x_data_u)\n",
        "        y_shuffle = np.copy(y_label)\n",
        "        for i in range(len(y_label)):\n",
        "            x_shuffle_m[i] = x_data_m[z[i]]\n",
        "            x_shuffle_u[i] = x_data_u[z[i]]\n",
        "            y_shuffle[i] = y_label[z[i]]\n",
        "        x_shuffle_m = x_shuffle_m.reshape([-1, 28, 28, 1])\n",
        "        x_shuffle_u = x_shuffle_u.reshape([-1, 28, 28, 1])/255\n",
        "        print(x_shuffle_m.shape)\n",
        "        print(x_shuffle_u.shape)\n",
        "        print(y_shuffle.shape)\n",
        "        print(x_shuffle_m[0])\n",
        "        print(x_shuffle_u[0])\n",
        "        # print(y_shuffle[0])\n",
        "        scio.savemat(path + '/2V_MNIST_USPS.mat', {'X1': x_shuffle_m, 'X2': x_shuffle_u, 'Y': y_shuffle})\n",
        "    data = scio.loadmat(path + \"/2V_MNIST_USPS.mat\")\n",
        "    x1 = data['X1']\n",
        "    x2 = data['X2']\n",
        "    Y = data['Y'][0]\n",
        "    ge = np.random.randint(0, len(x1), 1, dtype=int)\n",
        "    image1 = np.reshape(x1[ge], (28, 28))\n",
        "    image2 = np.reshape(x2[ge], (28, 28))\n",
        "    print(Y[ge][0])\n",
        "    plt.figure('Mnist')\n",
        "    plt.imshow(image1)\n",
        "    plt.show()\n",
        "    plt.figure('USPS')\n",
        "    plt.imshow(image2)\n",
        "    plt.show()\n",
        "    print(x1.shape)\n",
        "    print(x2.shape)\n",
        "    print(Y.shape)\n",
        "\n",
        "    return [x1, x2], Y\n",
        "\n",
        "Get_MNIST_USPS_From_COMIC()\n",
        "plt.ioff()  # Turn off interactive mode\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def Caltech101_20():\n",
        "    data = 0\n",
        "    if data == 1:\n",
        "        import scipy.io as scio\n",
        "        data = scio.loadmat(path + \"/Caltech101-20.mat\")\n",
        "        Y = data['Y'] - 1\n",
        "        # print(Y.shape)\n",
        "        X = data['X']\n",
        "        print(X[0][0].shape)\n",
        "        print(X[0][1].shape)\n",
        "        print(X[0][2].shape)\n",
        "        print(X[0][3].shape)\n",
        "        print(X[0][4].shape)\n",
        "        print(X[0][5].shape)\n",
        "        x1 = X[0][0]\n",
        "        x2 = X[0][1]\n",
        "        x3 = X[0][2]\n",
        "        x4 = X[0][3]\n",
        "        x5 = X[0][4]\n",
        "        x6 = X[0][5]\n",
        "        t = np.linspace(0, Y.shape[0] - 1, Y.shape[0], dtype=int)\n",
        "        print(t)\n",
        "        import random\n",
        "        random.shuffle(t)\n",
        "        # np.save(\"./Caltech101_20_t.npy\", t)\n",
        "        t = np.load(\"./Caltech101_20_t.npy\")\n",
        "        print(t)\n",
        "        xx1 = np.copy(x1)\n",
        "        xx2 = np.copy(x2)\n",
        "        xx3 = np.copy(x3)\n",
        "        xx4 = np.copy(x4)\n",
        "        xx5 = np.copy(x5)\n",
        "        xx6 = np.copy(x6)\n",
        "        YY = np.copy(Y)\n",
        "        for i in range(Y.shape[0]):\n",
        "            x1[i] = xx1[t[i]]\n",
        "            x2[i] = xx2[t[i]]\n",
        "            x3[i] = xx3[t[i]]\n",
        "            x4[i] = xx4[t[i]]\n",
        "            x5[i] = xx5[t[i]]\n",
        "            x6[i] = xx6[t[i]]\n",
        "            Y[i] = YY[t[i]]\n",
        "        from sklearn import preprocessing\n",
        "        min_max_scaler = preprocessing.MinMaxScaler()\n",
        "        x1 = min_max_scaler.fit_transform(x1)\n",
        "        x2 = min_max_scaler.fit_transform(x2)\n",
        "        x3 = min_max_scaler.fit_transform(x3)\n",
        "        x4 = min_max_scaler.fit_transform(x4)\n",
        "        x5 = min_max_scaler.fit_transform(x5)\n",
        "        x6 = min_max_scaler.fit_transform(x6)\n",
        "        print(x1[0])\n",
        "        Y = Y.reshape(Y.shape[0])\n",
        "        print(Y.shape)\n",
        "        scio.savemat(path + '/6V_Caltech101_20.mat', {'X1': x1, 'X2': x2, 'X3': x3, 'X4': x4, 'X5': x5, 'X6': x6, 'Y': Y})\n",
        "    import scipy.io as scio\n",
        "    data = scio.loadmat(path + \"/6V_Caltech101_20.mat\")\n",
        "    x1 = data['X1']\n",
        "    x2 = data['X2']\n",
        "    x3 = data['X3']\n",
        "    x4 = data['X4']\n",
        "    x5 = data['X5']\n",
        "    x6 = data['X6']\n",
        "    Y = data['Y'][0]\n",
        "    print(x1.shape)\n",
        "    print(x2.shape)\n",
        "    print(x3.shape)\n",
        "    print(x4.shape)\n",
        "    print(x5.shape)\n",
        "    print(x6.shape)\n",
        "    print(Y.shape)\n",
        "\n",
        "    return [x1, x2, x3, x4, x5, x6], Y\n",
        "\n",
        "Caltech101_20()\n",
        "plt.ioff()  # Turn off interactive mode\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def BDGP():\n",
        "    data = scio.loadmat(path + \"/2V_BDGP.mat\")\n",
        "    x1 = data['X1']\n",
        "    x2 = data['X2']\n",
        "    Y = data['Y'][0]\n",
        "\n",
        "    print(x1.shape)\n",
        "    print(x2.shape)\n",
        "    print(Y.shape)\n",
        "\n",
        "    # Example: Visualize the first sample in x1\n",
        "    plt.imshow(x1[0].reshape((50, 35)))  # Assuming you want to reshape to visualize as an image\n",
        "    plt.show()\n",
        "\n",
        "    return [x1, x2], Y\n",
        "\n",
        "BDGP()\n",
        "\n",
        "def load_data_conv(dataset):\n",
        "    print(\"load:\", dataset)\n",
        "    if dataset == 'Fashion_MV':                   # Fashion-10K-3views\n",
        "        return Fashion_MV()\n",
        "    elif dataset == 'MNIST_USPS':                 # MNIST-USPS\n",
        "        return Get_MNIST_USPS_From_COMIC()\n",
        "    elif dataset == 'Caltech101_20':              # Caltech101_20\n",
        "        return Caltech101_20()\n",
        "    elif dataset == 'BDGP':                       # BDGP\n",
        "        return BDGP()\n",
        "    else:\n",
        "        raise ValueError('Not defined for loading %s' % dataset)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, v_measure_score\n",
        "\n",
        "nmi = normalized_mutual_info_score\n",
        "vmeasure = v_measure_score\n",
        "ari = adjusted_rand_score\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Spk9N4Vt04LO",
        "outputId": "ccaacc36-3bee-465d-e153-9d6d80c99561"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'X1', 'X2', 'X3', 'Y'])\n",
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n",
            "4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 28, 28, 1)\n",
            "(5000, 28, 28, 1)\n",
            "(5000,)\n",
            "(2386, 48)\n",
            "(2386, 40)\n",
            "(2386, 254)\n",
            "(2386, 1984)\n",
            "(2386, 512)\n",
            "(2386, 928)\n",
            "(2386,)\n",
            "(2500, 1750)\n",
            "(2500, 79)\n",
            "(2500,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "x1, x2, and x3 have shapes (10000, 28, 28, 1), indicating 10,000 images each with dimensions 28x28 and a single channel.\n",
        "Y has shape (10000,), representing the labels for each image.\n",
        "\n"
      ],
      "metadata": {
        "id": "dVdaNG-l1MoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x1, x2, and x3 have shapes (5000, 28, 28, 1), indicating 10,000 images each with dimensions 28x28 and a single channel.\n",
        "Y has shape (5000,), representing the labels for each image.\n",
        "\n"
      ],
      "metadata": {
        "id": "I-GytbwE1xWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "six views with dimensions 48, 40, 254, 1984, 512, and 928 respectively, and the labels are a 1D array of size 2386.\n",
        "\n",
        "Data Preprocessing:\n",
        "\n",
        "Shuffling: The indices of the dataset are shuffled. This is a common practice to ensure the model does not learn any unintended order from the data.\n",
        "Normalization: Each view of the dataset is scaled using Min-Max normalization. This step is crucial for many machine learning algorithms to perform optimally."
      ],
      "metadata": {
        "id": "5NdaJkJHCSYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shapes of both views (x1 and x2) and the labels (Y) are printed. it's clear that each of the two views has 2500 samples, with x1 having 1750 features per sample and x2 having 79 features. The label array Y has 2500 entries, corresponding to the samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "n1p9DwU9Cxrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, v_measure_score\n",
        "\n",
        "nmi = normalized_mutual_info_score\n",
        "vmeasure = v_measure_score\n",
        "ari = adjusted_rand_score\n",
        "\n",
        "\n",
        "def acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate clustering accuracy. Require scikit-learn installed\n",
        "\n",
        "    # Arguments\n",
        "        y: true labels, numpy.array with shape `(n_samples,)`\n",
        "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
        "\n",
        "    # Return\n",
        "        accuracy, in [0,1]\n",
        "    \"\"\"\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "    from sklearn.utils.linear_assignment_ import linear_assignment\n",
        "    ind = linear_assignment(w.max() - w)\n",
        "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
      ],
      "metadata": {
        "id": "EsgNaJK1rfW0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import platform\n",
        "from sklearn.metrics import log_loss\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Conv1D, Conv2D, Conv2DTranspose, Flatten, Reshape, Conv3D, Conv3DTranspose, MaxPooling2D, Dropout, GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import Layer, InputSpec, Input, Dense, Multiply, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.initializers import VarianceScaling\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import Regularizer, l1, l2, l1_l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, SpectralClustering\n",
        "from sklearn.decomposition import PCA, SparsePCA\n",
        "from math import log\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "Rv3P4L9oFsFJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def FAE(dims, act='relu', view=1):\n",
        "    n_stacks = len(dims) - 1\n",
        "    init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
        "\n",
        "    input_name = 'v'+str(view)+'_'\n",
        "    # input\n",
        "    x = Input(shape=(dims[0],), name='input' + str(view))\n",
        "\n",
        "    h = x\n",
        "\n",
        "    # internal layers in encoder\n",
        "    for i in range(n_stacks-1):\n",
        "        h = Dense(dims[i + 1], activation=act, kernel_initializer=init, name=input_name+'encoder_%d' % i)(h)\n",
        "\n",
        "    # hidden layer\n",
        "    h = Dense(dims[-1], kernel_initializer=init, name='embedding' + str(view))(h)  # hidden layer, features are extracted from here\n",
        "\n",
        "    y = h\n",
        "    # internal layers in decoder\n",
        "    for i in range(n_stacks-1, 0, -1):\n",
        "        y = Dense(dims[i], activation=act, kernel_initializer=init, name=input_name+'decoder_%d' % i)(y)\n",
        "\n",
        "    # output\n",
        "    y = Dense(dims[0], kernel_initializer=init, name=input_name+'decoder_0')(y)\n",
        "\n",
        "    return Model(inputs=x, outputs=y, name=input_name+'Fae'), Model(inputs=x, outputs=h, name=input_name+'Fencoder')\n",
        "\n",
        "\n",
        "def MAE(view=2, filters=[32, 64, 128, 10], view_shape = [1, 2, 3]):\n",
        "    # print(len(view_shape[0]))\n",
        "    if len(view_shape[0]) == 1:\n",
        "        typenet = 'f-f'          # Fully connected networks\n",
        "    else:\n",
        "        typenet = 'c-c'          # Convolution networks\n",
        "\n",
        "    if typenet == 'c-c':\n",
        "        input1_shape = view_shape[0]\n",
        "        input2_shape = view_shape[1]\n",
        "        if input1_shape[0] % 8 == 0:\n",
        "            pad1 = 'same'\n",
        "        else:\n",
        "            pad1 = 'valid'\n",
        "        print(\"----------------------\")\n",
        "        print(filters)\n",
        "        input1 = Input(input1_shape, name='input1')\n",
        "        x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1_v1')(input1)\n",
        "        x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2_v1')(x)\n",
        "        x = Conv2D(filters[2], 3, strides=2, padding=pad1, activation='relu', name='conv3_v1')(x)\n",
        "        x = Flatten(name='Flatten1')(x)\n",
        "        x1 = Dense(units=filters[3], name='embedding1')(x)\n",
        "        x = Dense(units=filters[2]*int(input1_shape[0]/8)*int(input1_shape[0]/8), activation='relu',\n",
        "                  name='Dense1')(x1)\n",
        "        x = Reshape((int(input1_shape[0]/8), int(input1_shape[0]/8), filters[2]), name='Reshape1')(x)\n",
        "        x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad1, activation='relu', name='deconv3_v1')(x)\n",
        "        x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2_v1')(x)\n",
        "        x = Conv2DTranspose(input1_shape[2], 5, strides=2, padding='same', name='deconv1_v1')(x)\n",
        "\n",
        "        input2 = Input(input2_shape, name='input2')\n",
        "        xn = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1_v2')(input2)\n",
        "        xn = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2_v2')(xn)\n",
        "        xn = Conv2D(filters[2], 3, strides=2, padding=pad1, activation='relu', name='conv3_v2')(xn)\n",
        "        xn = Flatten(name='Flatten2')(xn)\n",
        "        x2 = Dense(units=filters[3], name='embedding2')(xn)\n",
        "        xn = Dense(units=filters[2] * int(input2_shape[0] / 8) * int(input2_shape[0] / 8), activation='relu',\n",
        "                   name='Dense2')(x2)\n",
        "        xn = Reshape((int(input2_shape[0] / 8), int(input2_shape[0] / 8), filters[2]), name='Reshape2')(xn)\n",
        "        xn = Conv2DTranspose(filters[1], 3, strides=2, padding=pad1, activation='relu', name='deconv3_v2')(xn)\n",
        "        xn = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2_v2')(xn)\n",
        "        xn = Conv2DTranspose(input2_shape[2], 5, strides=2, padding='same', name='deconv1_v2')(xn)\n",
        "        encoder1 = Model(inputs=input1, outputs=x1)\n",
        "        encoder2 = Model(inputs=input2, outputs=x2)\n",
        "        ae1 = Model(inputs=input1, outputs=x)\n",
        "        ae2 = Model(inputs=input2, outputs=xn)\n",
        "\n",
        "        if view == 2:\n",
        "            return [ae1, ae2], [encoder1, encoder2]\n",
        "        else:\n",
        "            input3_shape = view_shape[2]\n",
        "            input3 = Input(input3_shape, name='input3')\n",
        "            xr = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1_v3')(input3)\n",
        "            xr = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2_v3')(xr)\n",
        "            xr = Conv2D(filters[2], 3, strides=2, padding=pad1, activation='relu', name='conv3_v3')(xr)\n",
        "            xr = Flatten(name='Flatten3')(xr)\n",
        "            x3 = Dense(units=filters[3], name='embedding3')(xr)\n",
        "            xr = Dense(units=filters[2] * int(input3_shape[0] / 8) * int(input3_shape[0] / 8), activation='relu',\n",
        "                       name='Dense3')(x3)\n",
        "            xr = Reshape((int(input3_shape[0] / 8), int(input3_shape[0] / 8), filters[2]), name='Reshape3')(xr)\n",
        "            xr = Conv2DTranspose(filters[1], 3, strides=2, padding=pad1, activation='relu', name='deconv3_v3')(xr)\n",
        "            xr = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2_v3')(xr)\n",
        "            xr = Conv2DTranspose(input2_shape[2], 5, strides=2, padding='same', name='deconv1_v3')(xr)\n",
        "\n",
        "            encoder3 = Model(inputs=input3, outputs=x3)\n",
        "            ae3 = Model(inputs=input3, outputs=xr)\n",
        "\n",
        "            return [ae1, ae2, ae3], [encoder1, encoder2, encoder3]\n",
        "\n",
        "    if typenet == 'f-f':\n",
        "        ae = []\n",
        "        encoder = []\n",
        "        for v in range(view):\n",
        "            ae_tmp, encoder_tmp = FAE(dims=[view_shape[v][0], 500, 500, 2000, 10], view=v + 1)\n",
        "            ae.append(ae_tmp)\n",
        "            encoder.append(encoder_tmp)\n",
        "\n",
        "        return ae, encoder\n",
        "\n",
        "\n",
        "class ClusteringLayer(Layer):\n",
        "    \"\"\"\n",
        "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
        "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
        "\n",
        "    # Example\n",
        "    ```\n",
        "        model.add(ClusteringLayer(n_clusters=10))\n",
        "    ```\n",
        "    # Arguments\n",
        "        n_clusters: number of clusters.\n",
        "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
        "        alpha: parameter in Student's t-distribution. Default to 1.0.\n",
        "    # Input shape\n",
        "        2D tensor with shape: `(n_samples, n_features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
        "        super(ClusteringLayer, self).__init__(**kwargs)\n",
        "        self.n_clusters = n_clusters\n",
        "        self.alpha = alpha\n",
        "        self.initial_weights = weights\n",
        "        self.input_spec = InputSpec(ndim=2)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 2\n",
        "        input_dim = input_shape.as_list()[1]\n",
        "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
        "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
        "                 q_ij = 1/(1+dist(x_i, u_j)^2), then normalize it.\n",
        "        Arguments:\n",
        "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
        "        Return:\n",
        "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
        "        \"\"\"\n",
        "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
        "        q **= (self.alpha + 1.0) / 2.0\n",
        "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1))\n",
        "        return q\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape) == 2\n",
        "        return input_shape[0], self.n_clusters\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'n_clusters': self.n_clusters}\n",
        "        base_config = super(ClusteringLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class MvDEC(object):\n",
        "    def __init__(self,\n",
        "                 filters=[32, 64, 128, 10],\n",
        "                 #  view=2,\n",
        "                 n_clusters=10,\n",
        "                 alpha=1.0, view_shape = [1, 2, 3, 4, 5, 6]):\n",
        "\n",
        "        super(MvDEC, self).__init__()\n",
        "\n",
        "        self.view_shape = view_shape\n",
        "        self.filters = filters\n",
        "        self.n_clusters = n_clusters\n",
        "        self.alpha = alpha\n",
        "        self.pretrained = False\n",
        "        # prepare MvDEC model\n",
        "        self.view = len(view_shape)\n",
        "        # print(len(view_shape))\n",
        "\n",
        "        self.AEs, self.encoders = MAE(view=self.view, filters=self.filters, view_shape=self.view_shape)\n",
        "\n",
        "        Input = []\n",
        "        Output = []\n",
        "        Input_e = []\n",
        "        Output_e = []\n",
        "        clustering_layer = []\n",
        "\n",
        "        for v in range(self.view):\n",
        "                Input.append(self.AEs[v].input)\n",
        "                Output.append(self.AEs[v].output)\n",
        "                Input_e.append(self.encoders[v].input)\n",
        "                Output_e.append(self.encoders[v].output)\n",
        "                clustering_layer.append(ClusteringLayer(self.n_clusters, name='clustering'+str(v+1))(self.encoders[v].output))\n",
        "\n",
        "        self.autoencoder = Model(inputs=Input, outputs=Output)    # xin _ xout\n",
        "\n",
        "        self.encoder = Model(inputs=Input_e, outputs=Output_e)   # xin _ q\n",
        "\n",
        "        Output_m = []\n",
        "        for v in range(self.view):\n",
        "            Output_m.append(clustering_layer[v])\n",
        "            Output_m.append(Output[v])\n",
        "        self.model = Model(inputs=Input, outputs=Output_m)   # xin _ q _ xout\n",
        "\n",
        "    def pretrain(self, x, y, optimizer='adam', epochs=200, batch_size=256,\n",
        "                 save_dir='results/temp', verbose=0):\n",
        "        print('Begin pretraining: ', '-' * 60)\n",
        "        multi_loss = []\n",
        "        for view in range(len(x)):\n",
        "            multi_loss.append('mse')\n",
        "        self.autoencoder.compile(optimizer=optimizer, loss=multi_loss)\n",
        "        csv_logger = callbacks.CSVLogger(save_dir + '/T_pretrain_ae_log.csv')\n",
        "        save = '/ae_weights.h5'\n",
        "        cb = [csv_logger]\n",
        "        if y is not None and verbose > 0:\n",
        "            class PrintACC(callbacks.Callback):\n",
        "                def __init__(self, x, y, flag=1):\n",
        "                    self.x = x\n",
        "                    self.y = y\n",
        "                    self.flag = flag\n",
        "                    super(PrintACC, self).__init__()\n",
        "\n",
        "                def on_epoch_end(self, epoch, logs=None):\n",
        "                    time = 1    #  show k-means results on z\n",
        "                    if int(epochs / time) != 0 and (epoch+1) % int(epochs/time) != 0:\n",
        "                        # print(epoch)\n",
        "                        return\n",
        "                    view_name = 'embedding' + str(self.flag)\n",
        "                    feature_model = Model(self.model.input[self.flag - 1],\n",
        "                                              self.model.get_layer(name=view_name).output)\n",
        "\n",
        "                    features = feature_model.predict(self.x)\n",
        "                    km = KMeans(n_clusters=len(np.unique(self.y)), n_init=20, n_jobs=4)\n",
        "                    y_pred = km.fit_predict(features)\n",
        "                    print('\\n' + ' '*8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
        "                          % (Nmetrics.acc(self.y, y_pred), Nmetrics.nmi(self.y, y_pred)))\n",
        "\n",
        "            for view in range(len(x)):\n",
        "                cb.append(PrintACC(x[view], y, flag=view + 1))\n",
        "\n",
        "        # begin pretraining\n",
        "        t0 = time()\n",
        "        self.autoencoder.fit(x, x, batch_size=batch_size, epochs=epochs, callbacks=cb, verbose=verbose)\n",
        "\n",
        "        print('Pretraining time: ', time() - t0)\n",
        "        self.autoencoder.save_weights(save_dir + save)\n",
        "        print('Pretrained weights are saved to ' + save_dir + save)\n",
        "        self.pretrained = True\n",
        "        print('End pretraining: ', '-' * 60)\n",
        "\n",
        "    def load_weights(self, weights):  # load weights of models\n",
        "        self.model.load_weights(weights)\n",
        "\n",
        "    def predict_label(self, x):  # predict cluster labels using the output of clustering layer\n",
        "        input_dic = {}\n",
        "        for view in range(len(x)):\n",
        "            input_dic.update({'input' + str(view+1): x[view]})\n",
        "        Q_and_X = self.model.predict(input_dic, verbose=0)\n",
        "        y_pred = []\n",
        "        for view in range(len(x)):\n",
        "            # print(view)\n",
        "            y_pred.append(Q_and_X[view*2].argmax(1))\n",
        "\n",
        "        y_q = Q_and_X[(len(x)-1)*2]\n",
        "        for view in range(len(x) - 1):\n",
        "            y_q += Q_and_X[view*2]\n",
        "\n",
        "        # y_q = y_q/len(x)\n",
        "        y_mean_pred = y_q.argmax(1)\n",
        "        return y_pred, y_mean_pred\n",
        "\n",
        "    @staticmethod\n",
        "    def target_distribution(q):\n",
        "        weight = q ** 2 / q.sum(0)\n",
        "        # return q\n",
        "        return (weight.T / weight.sum(1)).T\n",
        "\n",
        "    def compile(self, optimizer='sgd', loss=['kld', 'mse'], loss_weights=[0.1, 1.0]):\n",
        "        self.model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights)\n",
        "\n",
        "    def train_on_batch(self, xin, yout, sample_weight=None):\n",
        "        return self.model.train_on_batch(xin, yout, sample_weight)\n",
        "\n",
        "    # DEMVC\n",
        "    def fit(self, arg, x, y, maxiter=2e4, batch_size=256, tol=1e-3,\n",
        "            UpdateCoo=200, save_dir='./results/tmp'):\n",
        "        print('Begin clustering:', '-' * 60)\n",
        "        print('Update Coo:', UpdateCoo)\n",
        "        save_interval = int(maxiter)  # only save the initial and final model\n",
        "        print('Save interval', save_interval)\n",
        "        # Step 1: initialize cluster centers using k-means\n",
        "        t1 = time()\n",
        "        ting = time() - t1\n",
        "        print(ting)\n",
        "\n",
        "        time_record = []\n",
        "        time_record.append(int(ting))\n",
        "        print(time_record)\n",
        "        print('Initializing cluster centers with k-means.')\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=100)\n",
        "\n",
        "        input_dic = {}\n",
        "        for view in range(len(x)):\n",
        "            input_dic.update({'input' + str(view+1): x[view]})\n",
        "        features = self.encoder.predict(input_dic)\n",
        "\n",
        "        y_pred = []\n",
        "        center = []\n",
        "\n",
        "        # --------------------------------------------\n",
        "        c = 1\n",
        "        if c == 1:\n",
        "            for view in range(len(x)):\n",
        "                y_pred.append(kmeans.fit_predict(features[view]))\n",
        "                np.save('TC'+str(view+1)+'.npy', [kmeans.cluster_centers_])\n",
        "                center.append(np.load('TC'+str(view+1)+'.npy'))\n",
        "        else:\n",
        "            from numpy import hstack\n",
        "            from sklearn import preprocessing\n",
        "            min_max_scaler = preprocessing.MinMaxScaler()\n",
        "            # n_features = []\n",
        "            # for view in range(len(x)):\n",
        "            #     n_features.append(min_max_scaler.fit_transform(features[view]))\n",
        "            #     # n_features.append(features[view])\n",
        "            # z = hstack(n_features)\n",
        "            z = hstack(features)\n",
        "            print(features[0].shape, len(x), z.shape)\n",
        "            y_pred.append(kmeans.fit_predict(z))\n",
        "            for view in range(len(x)-1):\n",
        "                y_pred.append(y_pred[0])\n",
        "            print(kmeans.cluster_centers_.shape)\n",
        "            centers = kmeans.cluster_centers_\n",
        "            for view in range(len(x)):\n",
        "                b = 10*view\n",
        "                e = b + 10\n",
        "                np.save('TC'+str(view+1)+'.npy', [centers[:, b:e]])\n",
        "                center.append(np.load('TC'+str(view+1)+'.npy'))\n",
        "        # --------------------------------------------\n",
        "\n",
        "        for view in range(len(x)):\n",
        "            acc = np.round(Nmetrics.acc(y, y_pred[view]), 5)\n",
        "            nmi = np.round(Nmetrics.nmi(y, y_pred[view]), 5)\n",
        "            vmea = np.round(Nmetrics.vmeasure(y, y_pred[view]), 5)\n",
        "            ari = np.round(Nmetrics.ari(y, y_pred[view]), 5)\n",
        "            print('Start-'+str(view+1)+': acc=%.5f, nmi=%.5f, v-measure=%.5f, ari=%.5f' % (acc, nmi, vmea, ari))\n",
        "\n",
        "        y_pred_last = []\n",
        "        y_pred_sp = []\n",
        "        for view in range(len(x)):\n",
        "            y_pred_last.append(y_pred[view])\n",
        "            y_pred_sp.append(y_pred[view])\n",
        "\n",
        "        for view in range(len(x)):\n",
        "            if arg.K12q == 0:\n",
        "                self.model.get_layer(name='clustering'+str(view+1)).set_weights(center[view])\n",
        "            else:\n",
        "                self.model.get_layer(name='clustering'+str(view+1)).set_weights(center[arg.K12q - 1])\n",
        "\n",
        "        # Step 2: deep clustering\n",
        "        # logging file\n",
        "        import csv\n",
        "        import os\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        logfile = open(save_dir + '/log.csv', 'w')\n",
        "        logwriter = csv.DictWriter(logfile, fieldnames=['iter', 'nmi', 'vmea', 'ari', 'loss'])\n",
        "        logwriter.writeheader()\n",
        "\n",
        "        index_array = np.arange(x[0].shape[0])\n",
        "        index = 0\n",
        "\n",
        "        Loss = []\n",
        "        avg_loss = []\n",
        "        for view in range(len(x)):\n",
        "            Loss.append(0)\n",
        "            avg_loss.append(0)\n",
        "\n",
        "        flag = 1\n",
        "\n",
        "        vf = arg.view_first\n",
        "\n",
        "        update_interval = arg.UpdateCoo\n",
        "\n",
        "        for ite in range(int(maxiter)):  # fine-turing\n",
        "\n",
        "            if ite % update_interval == 0:\n",
        "\n",
        "                Q_and_X = self.model.predict(input_dic)\n",
        "                # Coo\n",
        "                for view in range(len(x)):\n",
        "                    y_pred_sp[view] = Q_and_X[view*2].argmax(1)\n",
        "\n",
        "                # print(flag, (flag % len(x)))\n",
        "                # view_num = len(x)\n",
        "                q_index = (flag + vf - 1) % len(x)\n",
        "                if q_index == 0:\n",
        "                    q_index = len(x)\n",
        "                p = self.target_distribution(Q_and_X[(q_index-1) * 2])  # q->p\n",
        "                # print(q_index)\n",
        "                flag += 1\n",
        "                print('Next corresponding: p' + str(q_index))\n",
        "\n",
        "                P = []\n",
        "                if arg.Coo == 1:\n",
        "                    for view in range(len(x)):\n",
        "                        P.append(p)\n",
        "                else:\n",
        "                    for view in range(len(x)):\n",
        "                        P.append(self.target_distribution(Q_and_X[view*2]))\n",
        "\n",
        "                ge = np.random.randint(0, x[0].shape[0], 1, dtype=int)\n",
        "                ge = int(ge)\n",
        "                print('Number of sample:' + str(ge))\n",
        "                for view in range(len(x)):\n",
        "                    for i in Q_and_X[view*2][ge]:\n",
        "                        print(\"%.3f  \" % i, end=\"\")\n",
        "                    print(\"\\n\")\n",
        "\n",
        "                # evaluate the clustering performance\n",
        "                for view in range(len(x)):\n",
        "                    avg_loss[view] = Loss[view] / update_interval\n",
        "\n",
        "                for view in range(len(x)):\n",
        "                    Loss[view] = 0.\n",
        "\n",
        "                if y is not None:\n",
        "                    for num in range(self.n_clusters):\n",
        "                        same = np.where(y == num)\n",
        "                        same = np.array(same)[0]\n",
        "                        Out = y_pred_sp[len(x)-1][same]\n",
        "                        for view in range(len(x)-1):\n",
        "                            Out += y_pred_sp[view][same]\n",
        "\n",
        "                        out = Out\n",
        "                        comp = y_pred_sp[0][same]\n",
        "\n",
        "                        for i in range(len(out)):\n",
        "                            if Out[i]/len(x) == comp[i]:\n",
        "                                out[i] = 0\n",
        "                            else:\n",
        "                                out[i] = 1\n",
        "                        if (len(out) != 0):        # Simply calculate the scale of the alignment\n",
        "                            print('%d, %.2f%%, %d' % (num,len(np.array(np.where(out == 0))[0]) * 100/len(out),len(same)))\n",
        "                        else:\n",
        "                            print('%d, %.2f%%. %d' % (num, 0, len(same)))\n",
        "\n",
        "                    for view in range(len(x)):\n",
        "                        acc = np.round(Nmetrics.acc(y, y_pred_sp[view]), 5)\n",
        "                        nmi = np.round(Nmetrics.nmi(y, y_pred_sp[view]), 5)\n",
        "                        vme = np.round(Nmetrics.vmeasure(y, y_pred_sp[view]), 5)\n",
        "                        ari = np.round(Nmetrics.ari(y, y_pred_sp[view]), 5)\n",
        "                        logdict = dict(iter=ite, nmi=nmi, vmea=vme, ari=ari, loss=avg_loss[view])\n",
        "                        logwriter.writerow(logdict)\n",
        "                        logfile.flush()\n",
        "                        print('V'+str(view+1)+'-Iter %d: acc=%.5f, nmi=%.5f, v-measure=%.5f, ari=%.5f; loss=%.5f' % (\n",
        "                        ite, acc, nmi, vme, ari, avg_loss[view]))\n",
        "\n",
        "                    ting = time() - t1\n",
        "\n",
        "            # train on batch\n",
        "            idx = index_array[index * batch_size: min((index + 1) * batch_size, x[0].shape[0])]\n",
        "            x_batch = []\n",
        "            y_batch = []\n",
        "            for view in range(len(x)):\n",
        "                x_batch.append(x[view][idx])\n",
        "                y_batch.append(P[view][idx])\n",
        "                y_batch.append(x[view][idx])\n",
        "\n",
        "            tmp = self.train_on_batch(xin=x_batch, yout=y_batch)   # [y, xn, y, x]\n",
        "\n",
        "            for view in range(len(x)):\n",
        "                Loss[view] += tmp[2*view+1]\n",
        "\n",
        "            index = index + 1 if (index + 1) * batch_size <= x[0].shape[0] else 0\n",
        "            # ite += 1\n",
        "\n",
        "        # save the trained model\n",
        "        logfile.close()\n",
        "        # print('saving model to:', save_dir + '/model_final.h5')\n",
        "        # self.model.save_weights(save_dir + '/model_final.h5')\n",
        "        # self.autoencoder.save_weights(save_dir + '/pre_model.h5')\n",
        "        print('Clustering time: %ds' % (time() - t1))\n",
        "        print('End clustering:', '-' * 60)\n",
        "\n",
        "        Q_and_X = self.model.predict(input_dic)\n",
        "        y_pred = []\n",
        "        for view in range(len(x)):\n",
        "            y_pred.append(Q_and_X[view*2].argmax(1))\n",
        "\n",
        "        y_q = Q_and_X[(len(x)-1)*2]\n",
        "        for view in range(len(x) - 1):\n",
        "            y_q += Q_and_X[view*2]\n",
        "        # y_q = y_q/len(x)\n",
        "        y_mean_pred = y_q.argmax(1)\n",
        "        return y_pred, y_mean_pred\n",
        "\n",
        "    # SDMVC\n",
        "    def new_fit(self, arg, x, y, maxiter=2e4, batch_size=256, tol=1e-3,\n",
        "            UpdateCoo=200, save_dir='./results/tmp'):\n",
        "        print('Begin clustering:', '-' * 60)\n",
        "        print('Update Coo:', UpdateCoo)\n",
        "        save_interval = int(maxiter)  # only save the initial and final model\n",
        "        print('Save interval', save_interval)\n",
        "        # Step 1: initialize cluster centers using k-means\n",
        "        t1 = time()\n",
        "        ting = time() - t1\n",
        "        # print(ting)\n",
        "        time_record = []\n",
        "        time_record.append(int(ting))\n",
        "        # print(time_record)\n",
        "        print('Initializing cluster centers with k-means.')\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=100)\n",
        "\n",
        "        input_dic = {}\n",
        "        for view in range(len(x)):\n",
        "            input_dic.update({'input' + str(view + 1): x[view]})\n",
        "        features = self.encoder.predict(input_dic)\n",
        "\n",
        "        if len(x) <= 3:      # small trick: less view, more times to over arg.AR, so as to get high Aligned Rate\n",
        "            arg.ARtime = 3\n",
        "        else:\n",
        "            arg.ARtime = 2\n",
        "\n",
        "        y_pred = []\n",
        "        center = []\n",
        "\n",
        "        from numpy import hstack\n",
        "        from sklearn import preprocessing\n",
        "        min_max_scaler = preprocessing.MinMaxScaler()\n",
        "        # --------------------------------------------\n",
        "        c = 1\n",
        "        if c == 1:\n",
        "            for view in range(len(x)):\n",
        "                y_pred.append(kmeans.fit_predict(features[view]))\n",
        "                # np.save('TC' + str(view + 1) + '.npy', [kmeans.cluster_centers_])\n",
        "                # center.append(np.load('TC' + str(view + 1) + '.npy'))\n",
        "                center.append([kmeans.cluster_centers_])\n",
        "\n",
        "        elif c == 2:\n",
        "            n_features = []\n",
        "            for view in range(len(x)):\n",
        "                # n_features.append(min_max_scaler.fit_transform(features[view]))\n",
        "                n_features.append(features[view])\n",
        "            z = hstack(n_features)\n",
        "            print(features[0].shape, len(x), z.shape)\n",
        "            y_pred.append(kmeans.fit_predict(z))\n",
        "            for view in range(len(x) - 1):\n",
        "                y_pred.append(y_pred[0])\n",
        "            print(kmeans.cluster_centers_.shape)\n",
        "            centers = kmeans.cluster_centers_\n",
        "            # print(self.new_P(z, centers))\n",
        "            new_P = self.new_P(z, centers)\n",
        "            print(new_P.argmax(1))\n",
        "            print(y_pred[0])\n",
        "            for view in range(len(x)):\n",
        "                b = 10 * view\n",
        "                e = b + 10\n",
        "                np.save('TC' + str(view + 1) + '.npy', [centers[:, b:e]])\n",
        "                center.append(np.load('TC' + str(view + 1) + '.npy'))\n",
        "        else:\n",
        "            for view in range(len(x)):\n",
        "                y_pred.append(kmeans.fit_predict(features[view]))\n",
        "            print(\"random\")\n",
        "        # --------------------------------------------\n",
        "\n",
        "        for view in range(len(x)):\n",
        "            acc = np.round(Nmetrics.acc(y, y_pred[view]), 5)\n",
        "            nmi = np.round(Nmetrics.nmi(y, y_pred[view]), 5)\n",
        "            vmea = np.round(Nmetrics.vmeasure(y, y_pred[view]), 5)\n",
        "            ari = np.round(Nmetrics.ari(y, y_pred[view]), 5)\n",
        "            print('Start-' + str(view + 1) + ': acc=%.5f, nmi=%.5f, v-measure=%.5f, ari=%.5f' % (acc, nmi, vmea, ari))\n",
        "\n",
        "        y_pred_last = []\n",
        "        y_pred_sp = []\n",
        "        for view in range(len(x)):\n",
        "            y_pred_last.append(y_pred[view])\n",
        "            y_pred_sp.append(y_pred[view])\n",
        "\n",
        "        for view in range(len(x)):\n",
        "            # break\n",
        "            if arg.K12q == 0:\n",
        "                self.model.get_layer(name='clustering' + str(view + 1)).set_weights(center[view])\n",
        "            else:\n",
        "                self.model.get_layer(name='clustering' + str(view + 1)).set_weights(center[arg.K12q - 1])\n",
        "\n",
        "        # Step 2: deep clustering\n",
        "        # logging file\n",
        "        import csv\n",
        "        import os\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        logfile = open(save_dir + '/log.csv', 'w')\n",
        "        logwriter = csv.DictWriter(logfile, fieldnames=['iter', 'nmi', 'vmea', 'ari', 'loss'])\n",
        "        logwriter.writeheader()\n",
        "\n",
        "        index_array = np.arange(x[0].shape[0])\n",
        "        index = 0\n",
        "\n",
        "        Loss = []\n",
        "        avg_loss = []\n",
        "        kl_loss = []\n",
        "        for view in range(len(x)):\n",
        "            Loss.append(0)\n",
        "            avg_loss.append(0)\n",
        "            kl_loss.append(100000)\n",
        "\n",
        "        update_interval = arg.UpdateCoo\n",
        "        center_init = 0\n",
        "        alignment = 0\n",
        "        alignment_large = 0\n",
        "\n",
        "        ACC = []\n",
        "        NMI = []\n",
        "        ARI = []\n",
        "        vACC = []\n",
        "        vNMI = []\n",
        "        vARI = []\n",
        "        Rate = []\n",
        "        MVKLLoss = []\n",
        "        ite = 0\n",
        "        while True:\n",
        "            if ite % update_interval == 0:\n",
        "                print('\\n')\n",
        "                for view in range(len(x)):\n",
        "                    avg_loss[view] = Loss[view] / update_interval\n",
        "                    kl_loss[view] = kl_loss[view] / update_interval\n",
        "\n",
        "                Q_and_X = self.model.predict(input_dic)\n",
        "                # Coo\n",
        "                for view in range(len(x)):\n",
        "                    # print(Q_and_X[view * 2][0])\n",
        "                    y_pred_sp[view] = Q_and_X[view * 2].argmax(1)\n",
        "\n",
        "                features = self.encoder.predict(input_dic)\n",
        "                mu = []\n",
        "                for view in range(len(x)):\n",
        "                    muu = self.model.get_layer(name='clustering' + str(view + 1)).get_weights()\n",
        "                    # print(muu)\n",
        "                    mu.append(muu)\n",
        "\n",
        "                # np.save(save_dir + '/Features/' + str(ite) + '.npy', features)\n",
        "                # np.save(save_dir + '/Mu/' + str(ite) + '.npy', mu)\n",
        "                # print(features[0][0])\n",
        "                # print(features[1][0])\n",
        "\n",
        "                if len(x) >= 6:\n",
        "                    scaler = 1\n",
        "                else:\n",
        "                    scaler = 0\n",
        "                # print(\"scaler ? :\"+str(scaler))\n",
        "                # if views' number is too many (eg, >= 6), we can scale the features to [0,1] to build global features\n",
        "                if scaler == 1:\n",
        "                    n_features = []\n",
        "                    for view in range(len(x)):\n",
        "                        n_features.append(min_max_scaler.fit_transform(features[view]))\n",
        "                    z = hstack(n_features)\n",
        "                else:\n",
        "                    z = hstack(features)\n",
        "\n",
        "                kmean = KMeans(n_clusters=self.n_clusters, n_init=100)\n",
        "                y_pred = kmean.fit_predict(z)     # k-means on global features\n",
        "                print(kmeans.cluster_centers_.shape)\n",
        "                print(y_pred[0:9])\n",
        "\n",
        "                acc = np.round(Nmetrics.acc(y, y_pred), 5)\n",
        "                nmi = np.round(Nmetrics.nmi(y, y_pred), 5)\n",
        "                vmea = np.round(Nmetrics.vmeasure(y, y_pred), 5)\n",
        "                ari = np.round(Nmetrics.ari(y, y_pred), 5)\n",
        "                print('ACC=%.5f, NMI=%.5f, ARI=%.5f' % (acc, nmi, ari))\n",
        "                ACC.append(acc)\n",
        "                NMI.append(nmi)\n",
        "                ARI.append(ari)\n",
        "                the = np.sum(kl_loss) / len(x)\n",
        "                print(kl_loss)\n",
        "                print(Loss)\n",
        "                print(np.sum(kl_loss), np.sum(Loss))\n",
        "\n",
        "                if y is not None:\n",
        "\n",
        "                    scale = len(y)\n",
        "                    for i in range(len(y)):\n",
        "                        predict = y_pred_sp[0][i]\n",
        "                        for view in range(len(x) - 1):\n",
        "                            if predict == y_pred_sp[view + 1][i]:\n",
        "                                continue\n",
        "                            else:\n",
        "                                scale -= 1\n",
        "                                break\n",
        "\n",
        "                    # alignment_before = alignment\n",
        "                    alignment = (scale / len(y))\n",
        "                    print('Aligned Ratio: %.2f%%. %d' % (alignment * 100, len(y)))\n",
        "                    Rate.append(alignment)\n",
        "                    tmpACC = []\n",
        "                    tmpNMI = []\n",
        "                    tmpARI = []\n",
        "                    for view in range(len(x)):\n",
        "                        acc = np.round(Nmetrics.acc(y, y_pred_sp[view]), 5)\n",
        "                        nmi = np.round(Nmetrics.nmi(y, y_pred_sp[view]), 5)\n",
        "                        vme = np.round(Nmetrics.vmeasure(y, y_pred_sp[view]), 5)\n",
        "                        ari = np.round(Nmetrics.ari(y, y_pred_sp[view]), 5)\n",
        "                        logdict = dict(iter=ite, nmi=nmi, vmea=vme, ari=ari, loss=avg_loss[view])\n",
        "                        logwriter.writerow(logdict)\n",
        "                        logfile.flush()\n",
        "                        print('V' + str(\n",
        "                            view + 1) + '-Iter %d: ACC=%.5f, NMI=%.5f, ARI=%.5f; Loss=%.5f' % (\n",
        "                                  ite, acc, nmi, ari, avg_loss[view]))\n",
        "                        tmpACC.append(acc)\n",
        "                        tmpNMI.append(nmi)\n",
        "                        tmpARI.append(ari)\n",
        "                    vACC.append(tmpACC)\n",
        "                    vNMI.append(tmpNMI)\n",
        "                    vARI.append(tmpARI)\n",
        "                    ting = time() - t1\n",
        "\n",
        "                if alignment > arg.AR:\n",
        "                    alignment_large += 1\n",
        "                else:\n",
        "                    alignment_large = 0\n",
        "                # print(\"Over AR times:\" + str(alignment_large))\n",
        "                if alignment_large < arg.ARtime:\n",
        "                    Center_init = kmean.cluster_centers_    # k-means on global features\n",
        "                    new_P = self.new_P(z, Center_init)      # similarity measure\n",
        "                    print(\"Self-Supervised Multi-View Discriminative Feature Learning\")\n",
        "                    p = self.target_distribution(new_P)     # enhance discrimination\n",
        "                    center_init += 1\n",
        "                else:\n",
        "                    break\n",
        "                P = []\n",
        "                if arg.Coo == 1:\n",
        "                    print(\"Unified Target Distribution for Multiple KL Losses\")\n",
        "                    for view in range(len(x)):\n",
        "                        P.append(p)\n",
        "                else:\n",
        "                    print(\"self clustering\")\n",
        "                    for view in range(len(x)):\n",
        "                        P.append(self.target_distribution(Q_and_X[view * 2]))\n",
        "\n",
        "                # ge = np.random.randint(0, x[0].shape[0], 1, dtype=int)\n",
        "                # ge = int(ge)\n",
        "                # print('Number of sample:' + str(ge))\n",
        "                # for view in range(len(x)):\n",
        "                #     for i in Q_and_X[view * 2][ge]:\n",
        "                #         print(\"%.3f  \" % i, end=\"\")\n",
        "                #     print(\"\\n\")\n",
        "\n",
        "                # evaluate the clustering performance\n",
        "                for view in range(len(x)):\n",
        "                    Loss[view] = 0.\n",
        "                    kl_loss[view] = 0.\n",
        "\n",
        "            # train on batch\n",
        "            idx = index_array[index * batch_size: min((index + 1) * batch_size, x[0].shape[0])]\n",
        "            x_batch = []\n",
        "            y_batch = []\n",
        "            for view in range(len(x)):\n",
        "                x_batch.append(x[view][idx])\n",
        "                y_batch.append(P[view][idx])\n",
        "                y_batch.append(x[view][idx])\n",
        "\n",
        "            tmp = self.train_on_batch(xin=x_batch, yout=y_batch)  # [sum, q, xn, q, x]\n",
        "            # print(tmp)\n",
        "            KLLoss = []\n",
        "            for view in range(len(x)):\n",
        "                Loss[view] += tmp[2 * view + 2]       # lr\n",
        "                kl_loss[view] += tmp[2 * view + 1]    # lc\n",
        "                # KLLoss += tmp[2 * view + 1]\n",
        "                KLLoss.append(tmp[2 * view + 1])\n",
        "            MVKLLoss.append(KLLoss)\n",
        "            index = index + 1 if (index + 1) * batch_size <= x[0].shape[0] else 0\n",
        "            # print(ite)\n",
        "            ite += 1\n",
        "            if ite >= int(maxiter):\n",
        "                ite = 0\n",
        "                # # Train from scratch\n",
        "                # print(\"Pretrain self.autoencoder\")\n",
        "                # optimizer = Adam(lr=0.001)\n",
        "                # self.pretrain(x, y, optimizer=optimizer, epochs=500, batch_size=batch_size,\n",
        "                #               save_dir=save_dir, verbose=1)\n",
        "                print(\"self.autoencoder.load_weights(args.pretrain_dir)\")\n",
        "                self.autoencoder.load_weights(arg.pretrain_dir)\n",
        "                features = self.encoder.predict(input_dic)\n",
        "                for view in range(len(x)):\n",
        "                    kmeans.fit_predict(features[view])\n",
        "                    self.model.get_layer(name='clustering' + str(view + 1)).set_weights([kmeans.cluster_centers_])\n",
        "\n",
        "        # save the trained model\n",
        "        logfile.close()\n",
        "        # print('saving model to:', save_dir + '/model_final.h5')\n",
        "        # self.model.save_weights(save_dir + '/model_final.h5')\n",
        "        # # self.autoencoder.save_weights(save_dir + '/pre_model.h5')\n",
        "        # np.save(save_dir + '/AccNmiAriRate/ACC.npy', ACC)\n",
        "        # np.save(save_dir + '/AccNmiAriRate/NMI.npy', NMI)\n",
        "        # np.save(save_dir + '/AccNmiAriRate/ARI.npy', ARI)\n",
        "        # np.save(save_dir + '/AccNmiAriRate/vACC.npy', vACC)\n",
        "        # np.save(save_dir + '/AccNmiAriRate/vNMI.npy', vNMI)\n",
        "        # np.save(save_dir + '/AccNmiAriRate/vARI.npy', vARI)\n",
        "        # np.save(save_dir + '/AccNmiAriRate/Rate.npy', Rate)\n",
        "        # np.save(save_dir + '/AccNmiAriRate/MVKLLoss.npy', MVKLLoss)\n",
        "        print('Clustering time: %ds' % (time() - t1))\n",
        "        print('End clustering:', '-' * 60)\n",
        "\n",
        "        Q_and_X = self.model.predict(input_dic)\n",
        "        y_pred = []\n",
        "        for view in range(len(x)):\n",
        "            y_pred.append(Q_and_X[view * 2].argmax(1))\n",
        "\n",
        "        y_q = Q_and_X[(len(x) - 1) * 2]\n",
        "        for view in range(len(x) - 1):\n",
        "            y_q += Q_and_X[view * 2]\n",
        "        # y_q = y_q/len(x)\n",
        "        y_mean_pred = y_q.argmax(1)\n",
        "        return y_pred, y_mean_pred\n",
        "\n",
        "    def new_P(self, inputs, centers):\n",
        "        alpha = 1\n",
        "        q = 1.0 / (1.0 + (np.sum(np.square(np.expand_dims(inputs, axis=1) - centers), axis=2) / alpha))\n",
        "        q **= (alpha + 1.0) / 2.0\n",
        "        q = np.transpose(np.transpose(q) / np.sum(q, axis=1))\n",
        "        return q"
      ],
      "metadata": {
        "id": "ycnRAdA9Dgoc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import os\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "4geDAvEfFgmo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _make_data_and_model(args):\n",
        "    # prepare dataset\n",
        "    x, y = load_data_conv(args.dataset)\n",
        "    view = len(x)\n",
        "    view_shapes = []\n",
        "    Loss = []\n",
        "    Loss_weights = []\n",
        "    for v in range(view):\n",
        "        view_shapes.append(x[v].shape[1:])\n",
        "        Loss.append('kld')\n",
        "        Loss.append('mse')\n",
        "        Loss_weights.append(args.lc)\n",
        "        Loss_weights.append(args.Idec)\n",
        "    print(view_shapes)\n",
        "    print(Loss)\n",
        "    print(Loss_weights)\n",
        "    # prepare optimizer\n",
        "    optimizer = Adam(lr=args.lr)\n",
        "    # prepare the model\n",
        "    n_clusters = len(np.unique(y))\n",
        "    # n_clusters = 40   # over clustering\n",
        "    print(\"n_clusters:\" + str(n_clusters))\n",
        "    # lc = 0.1\n",
        "\n",
        "    model = MvDEC(filters=[32, 64, 128, 10], n_clusters=n_clusters, view_shape=view_shapes)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=Loss, loss_weights=Loss_weights)\n",
        "    return x, y, model\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    # get data and mode\n",
        "    x, y, model = _make_data_and_model(args)\n",
        "\n",
        "    model.model.summary()\n",
        "    # pretraining\n",
        "    t0 = time()\n",
        "    if not os.path.exists(args.save_dir):\n",
        "        os.makedirs(args.save_dir)\n",
        "    if args.pretrain_dir is not None and os.path.exists(args.pretrain_dir):  # load pretrained weights\n",
        "        model.autoencoder.load_weights(args.pretrain_dir)\n",
        "        # model.load_weights(args.pretrain_dir)\n",
        "    else:  # train\n",
        "        optimizer = Adam(lr=args.lr)\n",
        "        model.pretrain(x, y, optimizer=optimizer, epochs=args.pretrain_epochs,\n",
        "                            batch_size=args.batch_size, save_dir=args.save_dir, verbose=args.verbose)\n",
        "        args.pretrain_dir = args.save_dir + '/ae_weights.h5'\n",
        "    t1 = time()\n",
        "    print(\"Time for pretraining: %ds\" % (t1 - t0))\n",
        "\n",
        "    # clustering\n",
        "    # DEMVC, IDEC, DEC\n",
        "    # y_pred, y_mean_pred = model.fit(arg=args, x=x, y=y, maxiter=args.maxiter,\n",
        "    #                                            batch_size=args.batch_size, UpdateCoo=args.UpdateCoo,\n",
        "    #                                            save_dir=args.save_dir)\n",
        "    # SDMVC\n",
        "    y_pred, y_mean_pred = model.new_fit(arg=args, x=x, y=y, maxiter=args.maxiter,\n",
        "                                    batch_size=args.batch_size, UpdateCoo=args.UpdateCoo,\n",
        "                                    save_dir=args.save_dir)\n",
        "    if y is not None:\n",
        "        for view in range(len(x)):\n",
        "            print('Final: acc=%.4f, nmi=%.4f, ari=%.4f' %\n",
        "                    (Nmetrics.acc(y, y_pred[view]), Nmetrics.nmi(y, y_pred[view]), Nmetrics.ari(y, y_pred[view])))\n",
        "        print('Final: acc=%.4f, nmi=%.4f, ari=%.4f' %\n",
        "                  (Nmetrics.acc(y, y_mean_pred), Nmetrics.nmi(y, y_mean_pred), Nmetrics.ari(y, y_mean_pred)))\n",
        "\n",
        "    t2 = time()\n",
        "    print(\"Time for pretaining, clustering and total: (%ds, %ds, %ds)\" % (t1 - t0, t2 - t1, t2 - t0))\n",
        "    print('='*60)\n",
        "\n",
        "\n",
        "def test(args):\n",
        "    assert args.weights is not None\n",
        "\n",
        "    x, y, model = _make_data_and_model(args)\n",
        "    model.model.summary()\n",
        "    print('Begin testing:', '-' * 60)\n",
        "    model.load_weights(args.weights)\n",
        "    y_pred, y_mean_pred = model.predict_label(x=x)\n",
        "    if y is not None:\n",
        "        for view in range(len(x)):\n",
        "            print('Final: acc=%.4f, nmi=%.4f, ari=%.4f' %\n",
        "                    (Nmetrics.acc(y, y_pred[view]), Nmetrics.nmi(y, y_pred[view]), Nmetrics.ari(y, y_pred[view])))\n",
        "        print('Final: acc=%.4f, nmi=%.4f, ari=%.4f' %\n",
        "                  (Nmetrics.acc(y, y_mean_pred), Nmetrics.nmi(y, y_mean_pred), Nmetrics.ari(y, y_mean_pred)))\n",
        "\n",
        "    print('End testing:', '-' * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # -------------------------------------------------------\n",
        "    # Dataset settings\n",
        "    # 'MNIST_USPS'     # 2 views, 10 clusters,  5000 examples\n",
        "    # 'Fashion_MV'     # 3 views, 10 clusters, 10000 examples\n",
        "    # 'BDGP'           # 2 views,  5 clusters,  2500 examples\n",
        "    # 'Caltech101_20'  # 6 views, 20 clusters,  2386 examples\n",
        "    # -------------------------------------------------------\n",
        "    data = 'MNIST_USPS'\n",
        "    TEST = True        # Test the clustering performance of the trained models\n",
        "    # TEST = False\n",
        "    # Train_ae = True  # The stability of AE’s pre-training and K-means might be the bottleneck for AE/K-means based MVC\n",
        "    Train_ae = False   # The reported results are the average values after pre-training\n",
        "\n",
        "    AR = 0.90          # Aligned Ratio, e.g., 90%, the threshold that determines the stop condition\n",
        "    Coo = 1            # Unified P\n",
        "    View = 1           # View_first SetC for DEMVC\n",
        "    # K123q = View     # DEMVC\n",
        "    K123q = 0          # SDMVC\n",
        "    if Coo == 0:\n",
        "        K123q = 0      # K-means 1：k1 , 2：k2, 3：k3, 0: k-means, >view number: no settings centers\n",
        "\n",
        "    epochs = 500       # 500 epochs for pre-training AEs\n",
        "    Update_Coo = 1000  # Iterations to update self-supervised objective\n",
        "    Maxiter = 30000    # Max iterations for DEC, IDEC or DEMVC, not for SDMVC\n",
        "    Batch = 256        # Batch size\n",
        "    Idec = 1.0         # Dec 0.0 , Idec 1.0 --------  Reconstruction loss 1.0\n",
        "    lc = 0.1           # Clustering loss = 0.1\n",
        "    lrate = 0.001      # Learning rate = 0.001 ---- keras defult\n",
        "\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(description='main')\n",
        "\n",
        "    parser.add_argument('--dataset', default=data,\n",
        "                        help=\"Dataset name to train on\")\n",
        "    PATH = './content/drive/MyDrive/results/'\n",
        "    path = PATH + data\n",
        "    if Train_ae:\n",
        "        load = None\n",
        "    else:\n",
        "        load = path + '/ae_weights.h5'\n",
        "    if TEST:\n",
        "        load_test = path + '/model_final.h5'\n",
        "    else:\n",
        "        load_test = None\n",
        "\n",
        "    parser.add_argument('-d', '--save-dir', default=path,\n",
        "                        help=\"Dir to save the results\")\n",
        "    # Parameters for pretraining\n",
        "    parser.add_argument('--pretrain_dir', default=load, type=str,\n",
        "                        help=\"Pretrained weights of the autoencoder\")\n",
        "    parser.add_argument('--pretrain-epochs', default=epochs, type=int,   # 500\n",
        "                        help=\"Number of epochs for pretraining\")\n",
        "    parser.add_argument('-v', '--verbose', default=1, type=int,\n",
        "                        help=\"Verbose for pretraining\")\n",
        "    # Parameters for clustering\n",
        "    parser.add_argument('--testing', default=TEST, type=bool,\n",
        "                        help=\"Testing the clustering performance with provided weights\")\n",
        "    parser.add_argument('--weights', default=load_test, type=str,\n",
        "                        help=\"Model weights, used for testing\")\n",
        "    # pretrain_optimizer = 'adam'   # adam, sgd\n",
        "    # parser.add_argument('--optimizer', default=pretrain_optimizer, type=str,\n",
        "    #                     help=\"Optimizer for clustering phase\")\n",
        "    parser.add_argument('--lr', default=lrate, type=float,\n",
        "                        help=\"learning rate during clustering\")\n",
        "    parser.add_argument('--batch-size', default=Batch, type=int,   # 256\n",
        "                        help=\"Batch size\")\n",
        "    parser.add_argument('--maxiter', default=Maxiter, type=int,    # 2e4\n",
        "                        help=\"Maximum number of iterations\")\n",
        "    parser.add_argument('-uc', '--UpdateCoo', default=Update_Coo, type=int,   # 200\n",
        "                        help=\"Number of iterations to update the target distribution\")\n",
        "    parser.add_argument('--view_first', default=View, type=int,\n",
        "                        help=\"view-first\")\n",
        "    parser.add_argument('--Coo', default=Coo, type=int,\n",
        "                        help=\"Coo?\")\n",
        "    parser.add_argument('--K12q', default=K123q, type=int,\n",
        "                        help=\"Kmeans\")\n",
        "    parser.add_argument('--Idec', default=Idec, type=float,\n",
        "                        help=\"dec?\")\n",
        "    parser.add_argument('--lc', default=lc, type=float,\n",
        "                        help=\"Idec?\")\n",
        "    parser.add_argument('--AR', default=AR, type=float,\n",
        "                        help=\"aligned rate?\")\n",
        "    parser.add_argument('--ARtime', default=1, type=float,\n",
        "                        help=\"over aligned rate times?\")\n",
        "    args = parser.parse_args()\n",
        "    print('+' * 30, ' Parameters ', '+' * 30)\n",
        "    print(args)\n",
        "    print('+' * 75)\n",
        "    # testing\n",
        "    if args.testing:\n",
        "        test(args)\n",
        "    else:\n",
        "        train(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "PsvVfsOusfcQ",
        "outputId": "6492ff50-5b8d-470d-b89f-b920443401c3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--dataset DATASET] [-d SAVE_DIR]\n",
            "                                [--pretrain_dir PRETRAIN_DIR] [--pretrain-epochs PRETRAIN_EPOCHS]\n",
            "                                [-v VERBOSE] [--testing TESTING] [--weights WEIGHTS] [--lr LR]\n",
            "                                [--batch-size BATCH_SIZE] [--maxiter MAXITER] [-uc UPDATECOO]\n",
            "                                [--view_first VIEW_FIRST] [--Coo COO] [--K12q K12Q] [--Idec IDEC]\n",
            "                                [--lc LC] [--AR AR] [--ARtime ARTIME]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-3ecd287f-e95f-4b3c-b69a-485b68ad05f3.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    }
  ]
}